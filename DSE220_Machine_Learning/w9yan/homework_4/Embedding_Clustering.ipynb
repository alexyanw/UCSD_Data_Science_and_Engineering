{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 4 - DSE 220: Machine Learning\n",
    "English words embedding and clustering\n",
    "* data preprocessing\n",
    "* embedding\n",
    "* nearest neighbor\n",
    "* Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preprocessing ###\n",
    "\n",
    "**1**. First, download the Brown corpus (using nltk.corpus). This is a collection of text samples from a wide range of sources, with a total of over a million words. Calling brown.words() returns this text in one long list, which is useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "import nltk\n",
    "nltk.data.path.append(\"c:/wenyan/dse/w9yan/nltk_data\")\n",
    "#nltk.download()\n",
    "brown_words = brown.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2**. Remove stopwords and punctuation, make everything lowercase, and count how often each word occurs. Use this to come up with two lists:\n",
    "* A vocabulary V , consisting of a few thousand (e.g., 5000) of the most commonly-occurring words.\n",
    "* A shorter list C of at most 1000 of the most commonly-occurring words, which we shall call context words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "valid_words = [w.lower() for w in brown_words if w.lower() not in stopwords and re.search('^[a-z]+$', w.lower()) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "word_cnt = Counter(valid_words)\n",
    "vocabulary_count = word_cnt.most_common(5000)\n",
    "context_count = word_cnt.most_common(1000)\n",
    "vocabulary = [word[0] for word in vocabulary_count]\n",
    "context = [word[0] for word in context_count]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3**. For each word w in V , and each occurrence of it in the text stream, look at the surrounding window of four words (two before, two after): w1 w2 w w3 w4.\n",
    "\n",
    "Keep count of how often context words from C appear in these positions around word w. That is, for w in V , c in C, define n(w,c) = # of times c occurs in a window around w.\n",
    "\n",
    "Using these counts, construct the probability distribution Pr(c|w) of context words around w (for each w in V ), as well as the overall distribution Pr(c) of context words. These are distributions over C.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_c_around_w = {(w,c):0 for w in vocabulary for c in context}\n",
    "context_dict = {c:True for c in context}\n",
    "vocabulary_dict = {w:True for w in vocabulary}\n",
    "for i in range(2, len(valid_words)-2):\n",
    "    c = [0 for i in range(4)]\n",
    "    c[0],c[1],w,c[2],c[3] = valid_words[i-2:i+3]\n",
    "    if w not in vocabulary_dict: continue\n",
    "    for i in range(4):\n",
    "        if c[i] in context_dict:\n",
    "            count_c_around_w[(w,c[i])] += 1\n",
    "            \n",
    "# deal with 1st two and last two\n",
    "l = len(valid_words)\n",
    "for j in [0,1,l-2,l-1]:\n",
    "    w = valid_words[j]\n",
    "    if w not in vocabulary_dict: continue\n",
    "    for i in range(j+1,j+3):\n",
    "        if i >= l: break\n",
    "        c = valid_words[i]\n",
    "        if c in context_dict:\n",
    "            count_c_around_w[(w,c)] += 1\n",
    "    for i in range(j-2,j):\n",
    "        if i < 0: break\n",
    "        c = valid_words[i]\n",
    "        if c in context_dict:\n",
    "            count_c_around_w[(w,c)] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# P(c)=∑wn(w,c)/∑c′∑wn(w,c′)\n",
    "# P(c|w)=n(w,c)/∑c′n(w,c′)\n",
    "total_per_vocabulary = {w:0 for w in vocabulary}\n",
    "for (w,c) in count_c_around_w:\n",
    "    total_per_vocabulary[w] += count_c_around_w[(w,c)]\n",
    "# plus 1 smoothing for Pr(c|w)\n",
    "prob_c_under_w = {(w,c): count_c_around_w[(w,c)]+1 / total_per_vocabulary[w]+1000 for w in vocabulary for c in context}\n",
    "\n",
    "total_per_context = {c:0 for c in context}\n",
    "for (w,c) in count_c_around_w:\n",
    "    total_per_context[c] += count_c_around_w[(w,c)]\n",
    "total_occurance = sum(total_per_vocabulary.values())\n",
    "prob_context = {c: total_per_context[c]/total_occurance for c in context}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4**. Represent each vocabulary item w by a |C|-dimensional vector psi(w), whose c'th coordinate is: \n",
    "\n",
    "psi(w) = max(0, log(Pr(c|w)/Pr(c)))\n",
    "\n",
    "This is known as the (positive) pointwise mutual information, and has been quite successful in work on word embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "import pandas as pd\n",
    "\n",
    "def make_vector(w):\n",
    "    return [max(0, log(prob_c_under_w[(w,c)]/prob_context[c])) for c in context]\n",
    "\n",
    "vector_vocabulary = [[w]+make_vector(w) for w in vocabulary]\n",
    "\n",
    "X = pd.DataFrame(vector_vocabulary)\n",
    "X.columns = ['w']+context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one</th>\n",
       "      <th>would</th>\n",
       "      <th>said</th>\n",
       "      <th>new</th>\n",
       "      <th>could</th>\n",
       "      <th>time</th>\n",
       "      <th>two</th>\n",
       "      <th>may</th>\n",
       "      <th>first</th>\n",
       "      <th>like</th>\n",
       "      <th>...</th>\n",
       "      <th>lord</th>\n",
       "      <th>success</th>\n",
       "      <th>remain</th>\n",
       "      <th>principal</th>\n",
       "      <th>leadership</th>\n",
       "      <th>jack</th>\n",
       "      <th>obvious</th>\n",
       "      <th>fell</th>\n",
       "      <th>thin</th>\n",
       "      <th>pieces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.253008</td>\n",
       "      <td>11.429298</td>\n",
       "      <td>11.771546</td>\n",
       "      <td>11.879305</td>\n",
       "      <td>11.917345</td>\n",
       "      <td>11.923118</td>\n",
       "      <td>12.109214</td>\n",
       "      <td>12.062338</td>\n",
       "      <td>12.061258</td>\n",
       "      <td>12.208432</td>\n",
       "      <td>...</td>\n",
       "      <td>14.787721</td>\n",
       "      <td>14.713512</td>\n",
       "      <td>14.732785</td>\n",
       "      <td>14.729970</td>\n",
       "      <td>14.731785</td>\n",
       "      <td>14.808154</td>\n",
       "      <td>14.684853</td>\n",
       "      <td>14.796544</td>\n",
       "      <td>14.848437</td>\n",
       "      <td>14.767510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.244686</td>\n",
       "      <td>11.422777</td>\n",
       "      <td>11.780935</td>\n",
       "      <td>11.871485</td>\n",
       "      <td>11.889525</td>\n",
       "      <td>11.892639</td>\n",
       "      <td>12.046635</td>\n",
       "      <td>12.016544</td>\n",
       "      <td>12.047679</td>\n",
       "      <td>12.250911</td>\n",
       "      <td>...</td>\n",
       "      <td>14.783741</td>\n",
       "      <td>14.712514</td>\n",
       "      <td>14.739753</td>\n",
       "      <td>14.724982</td>\n",
       "      <td>14.731785</td>\n",
       "      <td>14.810148</td>\n",
       "      <td>14.681858</td>\n",
       "      <td>14.791557</td>\n",
       "      <td>14.847437</td>\n",
       "      <td>14.766511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.228775</td>\n",
       "      <td>11.422777</td>\n",
       "      <td>11.752497</td>\n",
       "      <td>11.860632</td>\n",
       "      <td>11.895345</td>\n",
       "      <td>11.879007</td>\n",
       "      <td>12.037790</td>\n",
       "      <td>12.031388</td>\n",
       "      <td>12.034902</td>\n",
       "      <td>12.196793</td>\n",
       "      <td>...</td>\n",
       "      <td>14.786728</td>\n",
       "      <td>14.711514</td>\n",
       "      <td>14.731785</td>\n",
       "      <td>14.725982</td>\n",
       "      <td>14.732785</td>\n",
       "      <td>14.814124</td>\n",
       "      <td>14.684854</td>\n",
       "      <td>14.792556</td>\n",
       "      <td>14.850433</td>\n",
       "      <td>14.766511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.197148</td>\n",
       "      <td>11.373940</td>\n",
       "      <td>11.721245</td>\n",
       "      <td>11.910932</td>\n",
       "      <td>11.868886</td>\n",
       "      <td>11.875078</td>\n",
       "      <td>12.035813</td>\n",
       "      <td>12.019530</td>\n",
       "      <td>12.045724</td>\n",
       "      <td>12.179076</td>\n",
       "      <td>...</td>\n",
       "      <td>14.780746</td>\n",
       "      <td>14.712514</td>\n",
       "      <td>14.731785</td>\n",
       "      <td>14.725982</td>\n",
       "      <td>14.732785</td>\n",
       "      <td>14.807155</td>\n",
       "      <td>14.681858</td>\n",
       "      <td>14.791557</td>\n",
       "      <td>14.848437</td>\n",
       "      <td>14.766511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.225941</td>\n",
       "      <td>11.382733</td>\n",
       "      <td>11.746712</td>\n",
       "      <td>11.859639</td>\n",
       "      <td>11.879750</td>\n",
       "      <td>11.883897</td>\n",
       "      <td>12.035813</td>\n",
       "      <td>12.017540</td>\n",
       "      <td>12.033913</td>\n",
       "      <td>12.186003</td>\n",
       "      <td>...</td>\n",
       "      <td>14.782744</td>\n",
       "      <td>14.714510</td>\n",
       "      <td>14.731785</td>\n",
       "      <td>14.724982</td>\n",
       "      <td>14.732785</td>\n",
       "      <td>14.810148</td>\n",
       "      <td>14.682858</td>\n",
       "      <td>14.791557</td>\n",
       "      <td>14.848437</td>\n",
       "      <td>14.767510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.234420</td>\n",
       "      <td>11.388553</td>\n",
       "      <td>11.733079</td>\n",
       "      <td>11.868537</td>\n",
       "      <td>11.886603</td>\n",
       "      <td>11.959954</td>\n",
       "      <td>12.036802</td>\n",
       "      <td>12.032370</td>\n",
       "      <td>12.103698</td>\n",
       "      <td>12.189940</td>\n",
       "      <td>...</td>\n",
       "      <td>14.781746</td>\n",
       "      <td>14.711514</td>\n",
       "      <td>14.733783</td>\n",
       "      <td>14.725982</td>\n",
       "      <td>14.732785</td>\n",
       "      <td>14.806156</td>\n",
       "      <td>14.682858</td>\n",
       "      <td>14.791557</td>\n",
       "      <td>14.847437</td>\n",
       "      <td>14.766511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.254848</td>\n",
       "      <td>11.376880</td>\n",
       "      <td>11.726193</td>\n",
       "      <td>11.863603</td>\n",
       "      <td>11.872850</td>\n",
       "      <td>11.871133</td>\n",
       "      <td>12.040747</td>\n",
       "      <td>12.023499</td>\n",
       "      <td>12.074656</td>\n",
       "      <td>12.182051</td>\n",
       "      <td>...</td>\n",
       "      <td>14.780746</td>\n",
       "      <td>14.711514</td>\n",
       "      <td>14.734781</td>\n",
       "      <td>14.729970</td>\n",
       "      <td>14.731785</td>\n",
       "      <td>14.806156</td>\n",
       "      <td>14.683856</td>\n",
       "      <td>14.791557</td>\n",
       "      <td>14.849435</td>\n",
       "      <td>14.776461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.219297</td>\n",
       "      <td>11.358114</td>\n",
       "      <td>11.731117</td>\n",
       "      <td>11.858646</td>\n",
       "      <td>11.865902</td>\n",
       "      <td>11.878026</td>\n",
       "      <td>12.034824</td>\n",
       "      <td>12.052769</td>\n",
       "      <td>12.032922</td>\n",
       "      <td>12.174098</td>\n",
       "      <td>...</td>\n",
       "      <td>14.781746</td>\n",
       "      <td>14.716502</td>\n",
       "      <td>14.732785</td>\n",
       "      <td>14.725982</td>\n",
       "      <td>14.732785</td>\n",
       "      <td>14.806156</td>\n",
       "      <td>14.683856</td>\n",
       "      <td>14.792557</td>\n",
       "      <td>14.847437</td>\n",
       "      <td>14.769507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.207802</td>\n",
       "      <td>11.378835</td>\n",
       "      <td>11.724217</td>\n",
       "      <td>11.874425</td>\n",
       "      <td>11.871861</td>\n",
       "      <td>11.938939</td>\n",
       "      <td>12.075566</td>\n",
       "      <td>12.022508</td>\n",
       "      <td>12.039836</td>\n",
       "      <td>12.177088</td>\n",
       "      <td>...</td>\n",
       "      <td>14.783742</td>\n",
       "      <td>14.712514</td>\n",
       "      <td>14.731785</td>\n",
       "      <td>14.725982</td>\n",
       "      <td>14.732785</td>\n",
       "      <td>14.807155</td>\n",
       "      <td>14.685850</td>\n",
       "      <td>14.792557</td>\n",
       "      <td>14.847437</td>\n",
       "      <td>14.767510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.206838</td>\n",
       "      <td>11.433930</td>\n",
       "      <td>11.737969</td>\n",
       "      <td>11.859639</td>\n",
       "      <td>11.875813</td>\n",
       "      <td>11.877044</td>\n",
       "      <td>12.034824</td>\n",
       "      <td>12.015546</td>\n",
       "      <td>12.028950</td>\n",
       "      <td>12.178083</td>\n",
       "      <td>...</td>\n",
       "      <td>14.782744</td>\n",
       "      <td>14.712514</td>\n",
       "      <td>14.731785</td>\n",
       "      <td>14.724983</td>\n",
       "      <td>14.731785</td>\n",
       "      <td>14.809151</td>\n",
       "      <td>14.682858</td>\n",
       "      <td>14.792557</td>\n",
       "      <td>14.851430</td>\n",
       "      <td>14.766511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.230660</td>\n",
       "      <td>11.382734</td>\n",
       "      <td>11.749609</td>\n",
       "      <td>11.861623</td>\n",
       "      <td>11.899206</td>\n",
       "      <td>11.871133</td>\n",
       "      <td>12.033833</td>\n",
       "      <td>12.023499</td>\n",
       "      <td>12.033913</td>\n",
       "      <td>12.201659</td>\n",
       "      <td>...</td>\n",
       "      <td>14.781746</td>\n",
       "      <td>14.711514</td>\n",
       "      <td>14.731785</td>\n",
       "      <td>14.724983</td>\n",
       "      <td>14.732785</td>\n",
       "      <td>14.806156</td>\n",
       "      <td>14.682858</td>\n",
       "      <td>14.791557</td>\n",
       "      <td>14.854413</td>\n",
       "      <td>14.766511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          one      would       said        new      could       time  \\\n",
       "0   11.253008  11.429298  11.771546  11.879305  11.917345  11.923118   \n",
       "1   11.244686  11.422777  11.780935  11.871485  11.889525  11.892639   \n",
       "2   11.228775  11.422777  11.752497  11.860632  11.895345  11.879007   \n",
       "3   11.197148  11.373940  11.721245  11.910932  11.868886  11.875078   \n",
       "4   11.225941  11.382733  11.746712  11.859639  11.879750  11.883897   \n",
       "5   11.234420  11.388553  11.733079  11.868537  11.886603  11.959954   \n",
       "6   11.254848  11.376880  11.726193  11.863603  11.872850  11.871133   \n",
       "7   11.219297  11.358114  11.731117  11.858646  11.865902  11.878026   \n",
       "8   11.207802  11.378835  11.724217  11.874425  11.871861  11.938939   \n",
       "9   11.206838  11.433930  11.737969  11.859639  11.875813  11.877044   \n",
       "10  11.230660  11.382734  11.749609  11.861623  11.899206  11.871133   \n",
       "\n",
       "          two        may      first       like    ...           lord  \\\n",
       "0   12.109214  12.062338  12.061258  12.208432    ...      14.787721   \n",
       "1   12.046635  12.016544  12.047679  12.250911    ...      14.783741   \n",
       "2   12.037790  12.031388  12.034902  12.196793    ...      14.786728   \n",
       "3   12.035813  12.019530  12.045724  12.179076    ...      14.780746   \n",
       "4   12.035813  12.017540  12.033913  12.186003    ...      14.782744   \n",
       "5   12.036802  12.032370  12.103698  12.189940    ...      14.781746   \n",
       "6   12.040747  12.023499  12.074656  12.182051    ...      14.780746   \n",
       "7   12.034824  12.052769  12.032922  12.174098    ...      14.781746   \n",
       "8   12.075566  12.022508  12.039836  12.177088    ...      14.783742   \n",
       "9   12.034824  12.015546  12.028950  12.178083    ...      14.782744   \n",
       "10  12.033833  12.023499  12.033913  12.201659    ...      14.781746   \n",
       "\n",
       "      success     remain  principal  leadership       jack    obvious  \\\n",
       "0   14.713512  14.732785  14.729970   14.731785  14.808154  14.684853   \n",
       "1   14.712514  14.739753  14.724982   14.731785  14.810148  14.681858   \n",
       "2   14.711514  14.731785  14.725982   14.732785  14.814124  14.684854   \n",
       "3   14.712514  14.731785  14.725982   14.732785  14.807155  14.681858   \n",
       "4   14.714510  14.731785  14.724982   14.732785  14.810148  14.682858   \n",
       "5   14.711514  14.733783  14.725982   14.732785  14.806156  14.682858   \n",
       "6   14.711514  14.734781  14.729970   14.731785  14.806156  14.683856   \n",
       "7   14.716502  14.732785  14.725982   14.732785  14.806156  14.683856   \n",
       "8   14.712514  14.731785  14.725982   14.732785  14.807155  14.685850   \n",
       "9   14.712514  14.731785  14.724983   14.731785  14.809151  14.682858   \n",
       "10  14.711514  14.731785  14.724983   14.732785  14.806156  14.682858   \n",
       "\n",
       "         fell       thin     pieces  \n",
       "0   14.796544  14.848437  14.767510  \n",
       "1   14.791557  14.847437  14.766511  \n",
       "2   14.792556  14.850433  14.766511  \n",
       "3   14.791557  14.848437  14.766511  \n",
       "4   14.791557  14.848437  14.767510  \n",
       "5   14.791557  14.847437  14.766511  \n",
       "6   14.791557  14.849435  14.776461  \n",
       "7   14.792557  14.847437  14.769507  \n",
       "8   14.792557  14.847437  14.767510  \n",
       "9   14.792557  14.851430  14.766511  \n",
       "10  14.791557  14.854413  14.766511  \n",
       "\n",
       "[11 rows x 1000 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.ix[:10,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding ###\n",
    "- Suppose we want a 100-dimensional representation. How would you achieve this?\n",
    "\n",
    "Tried both SVD and PCA although SVD is my choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVD\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=100, random_state=42)\n",
    "X_svd = svd.fit_transform(X.ix[:,1:]) \n",
    "\n",
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=100)\n",
    "X_pca = pca.fit_transform(X.ix[:,1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6**. Investigate the resulting embedding in two ways:\n",
    "* Try finding the nearest neighbor of selected words. Do the answers make sense?\n",
    "* Cluster the vocabulary into 100 clusters. Look them over; do they seem completely random, or is there some sense to them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest neighbor results ###\n",
    "\n",
    "Pick a collection of 25 words w from V. For each w, return its nearest neighbor w0 != w in V. A popular distance measure to use for this is cosine distance:\n",
    "\n",
    "1 -\tpsi(w).psi(w0) / (||psi(w)|| * ||psi(w0)||)\n",
    "\n",
    "Here are some suggestions for words you might choose:\n",
    "communism, autumn, cigarette, pulmonary, mankind, africa, chicago, rev-\n",
    "olution, september, chemical, detergent, dictionary, storm, worship\n",
    "\n",
    "Do the results make any sense? You can use other distance measures apart from cosine distance to improve the results. (20 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "check_words = ['communism', 'autumn', 'cigarette', 'pulmonary', 'mankind', 'africa', 'chicago', 'revolution', 'september', 'chemical', 'detergent', 'dictionary', 'storm', 'worship', 'war', 'problem', 'wall', 'department', 'society', 'company', 'college', 'public', 'money', 'wife', 'wanted']\n",
    "check_words_index = [vocabulary.index(w) for w in check_words]\n",
    "\n",
    "def compute_distance(v0, v1):\n",
    "    dist= 1 - np.dot(v0,v1) / (np.linalg.norm(v0) * np.linalg.norm(v1))\n",
    "    return dist\n",
    "\n",
    "def find_nearest_neighbor(X):\n",
    "    for j in check_words_index:\n",
    "        nearest_neighbor = -1\n",
    "        nearest_dist = 1000\n",
    "        v0 = X[j]\n",
    "        w0 = vocabulary[j]\n",
    "        for i in range(len(vocabulary)):\n",
    "            if i == j: continue\n",
    "            v1 = X[i]\n",
    "            dist = compute_distance(v0, v1)\n",
    "            if dist < nearest_dist:\n",
    "                nearest_dist = dist\n",
    "                nearest_neighbor = i\n",
    "        w1 = vocabulary[nearest_neighbor]\n",
    "        print(\"nearest neighbor of {} - {}\".format(w0, w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nearest neighbor of communism - losing\n",
      "nearest neighbor of autumn - tournament\n",
      "nearest neighbor of cigarette - pitch\n",
      "nearest neighbor of pulmonary - disk\n",
      "nearest neighbor of mankind - judgments\n",
      "nearest neighbor of africa - carolina\n",
      "nearest neighbor of chicago - university\n",
      "nearest neighbor of revolution - journey\n",
      "nearest neighbor of september - january\n",
      "nearest neighbor of chemical - symbolic\n",
      "nearest neighbor of detergent - fabrics\n",
      "nearest neighbor of dictionary - text\n",
      "nearest neighbor of storm - weekend\n",
      "nearest neighbor of worship - skywave\n",
      "nearest neighbor of war - free\n",
      "nearest neighbor of problem - fact\n",
      "nearest neighbor of wall - street\n",
      "nearest neighbor of department - welfare\n",
      "nearest neighbor of society - community\n",
      "nearest neighbor of company - power\n",
      "nearest neighbor of college - university\n",
      "nearest neighbor of public - education\n",
      "nearest neighbor of money - better\n",
      "nearest neighbor of wife - woman\n",
      "nearest neighbor of wanted - want\n"
     ]
    }
   ],
   "source": [
    "find_nearest_neighbor(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nearest neighbor of communism - losing\n",
      "nearest neighbor of autumn - tournament\n",
      "nearest neighbor of cigarette - pitch\n",
      "nearest neighbor of pulmonary - disk\n",
      "nearest neighbor of mankind - defeat\n",
      "nearest neighbor of africa - carolina\n",
      "nearest neighbor of chicago - carleton\n",
      "nearest neighbor of revolution - resumed\n",
      "nearest neighbor of september - january\n",
      "nearest neighbor of chemical - description\n",
      "nearest neighbor of detergent - mustard\n",
      "nearest neighbor of dictionary - text\n",
      "nearest neighbor of storm - aristotle\n",
      "nearest neighbor of worship - produces\n",
      "nearest neighbor of war - free\n",
      "nearest neighbor of problem - subject\n",
      "nearest neighbor of wall - block\n",
      "nearest neighbor of department - secretary\n",
      "nearest neighbor of society - politics\n",
      "nearest neighbor of company - letters\n",
      "nearest neighbor of college - university\n",
      "nearest neighbor of public - education\n",
      "nearest neighbor of money - drink\n",
      "nearest neighbor of wife - husband\n",
      "nearest neighbor of wanted - maybe\n"
     ]
    }
   ],
   "source": [
    "find_nearest_neighbor(X_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering ###\n",
    "\n",
    "Using the vectorial representation \tpsi(), cluster the words in V into 100 groups. Clearly specify what algorithm and distance function you using for this, and the reasons for your choices.\n",
    "\n",
    "Look over the resulting 100 clusters. Do any of them seem even moderately coherent? Pick out a few of the best clusters and list the words in them. (30 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Both Kmeans++ and EM(GaussianMixture) are tried here although EM is my choice.\n",
    "* For Kmeans++, also tried to find best value for param n_init based on inertia, both embedding of PCA and SVD are experimented with.\n",
    "* For GaussianMixture, tried all covariance type and decided to use 'full' for covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def check_kmeans_n_init(X):\n",
    "    inertia = []\n",
    "    n_init_list = np.arange(1,30,5)\n",
    "\n",
    "    for n in n_init_list: \n",
    "        k_means = KMeans(n_clusters=100, n_init=n, init='k-means++', random_state=5) \n",
    "        k_means.fit(X)\n",
    "        inertia.append(k_means.inertia_)\n",
    "    plt.plot(n_init_list, inertia)\n",
    "    plt.show()\n",
    "\n",
    "def group_with_kmeans(X, n):\n",
    "    inertia = []\n",
    "    k_means = KMeans(n_clusters=100, n_init=n, init='k-means++', random_state=5) \n",
    "    k_means.fit(X)\n",
    "    return k_means.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBDMzAxwIZmaWcCCYmRkA/x+jDAFSoKzugAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x132c7bad2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_kmeans_n_init(X_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['never', 'know', 'say', 'think']\n",
      "['government', 'president', 'america', 'nations']\n",
      "['later', 'several', 'four', 'five', 'past', 'six', 'ten']\n",
      "['small', 'general', 'less', 'enough', 'far', 'end', 'order', 'possible', 'early', 'case', 'need', 'become', 'perhaps', 'seem']\n",
      "['system', 'social', 'political', 'economic']\n",
      "['around', 'went', 'got', 'going']\n",
      "['american', 'part', 'number', 'fact', 'hand', 'point', 'side', 'large', 'best', 'least', 'example']\n",
      "['age', 'following', 'century', 'million', 'recent', 'miles', 'earlier', 'nearly', 'throughout', 'month', 'couple', 'fiscal', 'lived', 'seven', 'married', 'spent', 'eight', 'june', 'dollars', 'thousand', 'older', 'nine', 'twenty', 'fifty', 'thirty', 'fifteen', 'forty']\n",
      "['program', 'business', 'national', 'development', 'interest', 'service', 'law', 'local', 'college', 'federal', 'board', 'community', 'court', 'department', 'policy', 'education', 'university', 'washington', 'schools', 'secretary', 'administration']\n",
      "['home', 'thought', 'left', 'course', 'away', 'put', 'better', 'told', 'knew', 'give', 'things', 'want', 'done', 'tell', 'sure']\n",
      "['form', 'thus', 'lines', 'values', 'space', 'range', 'points', 'temperature', 'c', 'function', 'cells', 'address', 'p', 'cell', 'operator', 'bond', 'q', 'curve', 'polynomial']\n",
      "['water', 'head', 'eyes', 'toward', 'room', 'face', 'along', 'light', 'turned', 'open', 'began', 'hands', 'feet', 'across', 'car', 'behind', 'office', 'street', 'front', 'stood', 'road', 'women', 'dark', 'moved', 'walked', 'opened']\n",
      "['city', 'members', 'central', 'england', 'birth', 'orleans', 'jersey']\n",
      "['used', 'use', 'without', 'place', 'however', 'found', 'find']\n",
      "['days', 'times', 'minutes', 'months', 'hours', 'weeks']\n",
      "['always', 'almost', 'took', 'yet', 'asked', 'john', 'big', 'felt', 'saw', 'seemed', 'mind', 'god', 'name', 'seen', 'word', 'heard', 'moment', 'boy', 'love', 'woman', 'girl']\n",
      "\n",
      "max group: 2453\n"
     ]
    }
   ],
   "source": [
    "# check svd grouping\n",
    "X['label'] = group_with_kmeans(X_svd, 6)\n",
    "\n",
    "# print groups out of 100 which has more than 5 words\n",
    "max_group = []\n",
    "for i in range(100):\n",
    "    group = X[X['label']==i]['w'].tolist()\n",
    "    length = len(group)\n",
    "    if length > len(max_group): max_group = group\n",
    "    if length < 30 and length >3:\n",
    "        print(group)\n",
    "print(\"\\nmax group:\",len(max_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwCjrBKNcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x132ca58ca90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_kmeans_n_init(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check pca grouping\n",
    "X['label'] = group_with_kmeans(X_pca, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['little', 'right', 'thought', 'say', 'something', 'think']\n",
      "['give', 'become', 'help', 'probably', 'turn', 'cost', 'seem', 'provide', 'run', 'leave', 'believe', 'soon', 'longer', 'call', 'expected', 'hope', 'bring', 'expect']\n",
      "['however', 'part', 'fact', 'less', 'point', 'present', 'important', 'early', 'need', 'perhaps']\n",
      "['since', 'place', 'every', 'end', 'next', 'days', 'second', 'half']\n",
      "['great', 'used', 'use', 'found', 'almost', 'possible', 'things', 'children', 'best', 'others', 'times', 'seen']\n",
      "['left', 'hand', 'side', 'thing']\n",
      "['might', 'without', 'around', 'course', 'always', 'away', 'enough', 'far', 'better', 'told', 'nothing', 'find', 'going', 'asked', 'knew', 'felt', 'want', 'done', 'anything', 'really', 'tell', 'sure']\n",
      "['later', 'several', 'five', 'past', 'ten']\n",
      "['city', 'development', 'members', 'central', 'england', 'birth', 'orleans', 'jersey']\n",
      "['came', 'home', 'went', 'got', 'put', 'head', 'turned']\n",
      "['order', 'form', 'thus', 'line', 'lines', 'values', 'space', 'range', 'points', 'temperature', 'c', 'function', 'address', 'p', 'cell', 'operator', 'bond', 'q', 'curve', 'polynomial']\n",
      "['took', 'eyes', 'toward', 'room', 'face', 'big', 'along', 'saw', 'open', 'door', 'feet', 'across', 'car', 'behind', 'street', 'front', 'stood', 'walked', 'opened']\n",
      "['program', 'national', 'service', 'law', 'local', 'college', 'board', 'policy', 'education', 'university', 'students', 'schools', 'research', 'defense', 'medical', 'training', 'programs', 'vocational']\n",
      "['age', 'six', 'million', 'minutes', 'months', 'recent', 'hours', 'miles', 'earlier', 'weeks', 'month', 'couple', 'seven', 'eight', 'dollars', 'thousand', 'nine', 'twenty', 'fifty', 'thirty', 'fifteen', 'forty']\n",
      "['american', 'general', 'upon', 'number', 'system', 'group', 'social', 'large', 'within', 'interest', 'area', 'whole', 'human', 'history', 'political', 'economic', 'community']\n"
     ]
    }
   ],
   "source": [
    "# print groups out of 100 which has more than 5 words\n",
    "for i in range(100):\n",
    "    group = X[X['label']==i]['w'].tolist()\n",
    "    if len(group) > 3 and len(group) < 30:\n",
    "        print(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EM(GaussianMixture) ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cov_type:spherical, log likelihood:557.1509100504013\n",
      "cov_type:diag, log likelihood:559.6455782429762\n",
      "cov_type:tied, log likelihood:548.8795062419473\n",
      "cov_type:full, log likelihood:572.0598569310584\n"
     ]
    }
   ],
   "source": [
    "# EM clustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "for cov_type in ['spherical', 'diag', 'tied', 'full']:\n",
    "#for iter in [5, 10, 20, 40]:\n",
    "    gmm = GaussianMixture(n_components=100, covariance_type=cov_type, random_state=0)\n",
    "    gmm.fit(X_svd)\n",
    "    print(\"cov_type:{}, log likelihood:{}\".format(cov_type,gmm.lower_bound_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['john', 'god', 'name', 'death', 'word', 'words', 'miss', 'heard', 'boy', 'love', 'wife', 'voice', 'woman', 'girl', 'mother', 'mean', 'alone', 'gone', 'father', 'dead', 'son', 'police', 'hear', 'yes', 'remember', 'oh']\n",
      "['also', 'used', 'use', 'find']\n",
      "['since', 'american', 'however', 'part', 'number', 'less', 'given', 'order', 'form', 'thus']\n",
      "['say', 'told', 'nothing', 'knew', 'give', 'want', 'anything', 'really', 'tell', 'sure']\n",
      "['second', 'early', 'half', 'period', 'close', 'short', 'million', 'third', 'spent']\n",
      "['good', 'still', 'come', 'thought', 'think']\n",
      "['great', 'something', 'look', 'things', 'thing']\n",
      "['later', 'several', 'four', 'five', 'past', 'six', 'recent', 'hundred', 'ten']\n",
      "['put', 'head', 'eyes', 'toward', 'room', 'turned', 'open', 'feet', 'across', 'car', 'behind', 'street', 'front', 'stood', 'moved', 'walked', 'opened']\n",
      "['law', 'federal', 'department', 'secretary']\n",
      "['general', 'public', 'system', 'program', 'business', 'group', 'national', 'within', 'development', 'interest', 'area', 'service', 'political', 'economic', 'community']\n",
      "['without', 'left', 'course', 'away', 'hand', 'far', 'side', 'big', 'best', 'ever', 'least']\n",
      "['days', 'minutes', 'months', 'hours', 'weeks']\n",
      "['city', 'members', 'england', 'orleans']\n",
      "['become', 'help', 'whether', 'act', 'probably', 'result', 'turn', 'cost', 'seem', 'provide', 'run', 'plan', 'leave', 'believe', 'soon', 'increase', 'longer', 'call', 'expected', 'return', 'hope', 'pay', 'bring', 'certainly', 'decided', 'appear', 'expect']\n",
      "['found', 'always', 'almost', 'enough', 'took', 'yet', 'end', 'asked', 'looked', 'felt', 'saw', 'seemed', 'seen']\n",
      "['came', 'right', 'around', 'went', 'got', 'going']\n",
      "['small', 'water', 'set', 'called', 'president', 'face', 'large', 'children', 'church', 'light', 'family', 'mind', 'country', 'taken', 'body', 'already', 'moment', 'clear', 'morning']\n"
     ]
    }
   ],
   "source": [
    "gmm = GaussianMixture(n_components=100, covariance_type='full', random_state=0)\n",
    "gmm.fit(X_svd)\n",
    "X['label'] = gmm.predict(X_svd)\n",
    "# print groups out of 100 which has more than 5 words\n",
    "for i in range(100):\n",
    "    group = X[X['label']==i]['w'].tolist()\n",
    "    if len(group) > 3 and len(group) < 30:\n",
    "        print(group)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
